{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "47HJVccFHOI_",
        "TyBw3hN0HQan",
        "HXixhjYa1uMD",
        "dQYNfB8fPOxa"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EPatha/BK_Data-Scientist/blob/main/Copy_of_FIXME_Study_Case_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://dinus.ac.id/wp-content/uploads/2024/11/Logo-Web-Udinus-Putih.png\"  width=\"400\">\n",
        "\n",
        "\n",
        "# BK Associate Data Scientist - Teknik Informatika S1 - 'TANGGAL' 2025\n",
        "</center>"
      ],
      "metadata": {
        "id": "ko7vfqQlYWym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PANDUAN:\n",
        "- **WAJIB MENGISI SEMUA UNIT**\n",
        "- DIPERBOLEHKAN MEMBUKA FILE LAMPAU, TAPI TIDAK BOLEH MENGGUNAKAN CHATGPT, GEMINI, CLAUDE, DAN LLM LAINNYA\n",
        "- JIKA SUDAH SELESAI, SILAKAN MENGABARI TIM ASISTEN UNTUK DISKUSI JADWAL PRESENTASI"
      ],
      "metadata": {
        "id": "XqhePs6nYdty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Latar Belakang Masalah\n",
        "Penyakit hati (*liver disease*) merupakan salah satu penyebab utama morbiditas dan mortalitas di seluruh dunia, terutama di negara-negara berkembang seperti India. Deteksi dini dan diagnosis penyakit hati sangat penting untuk mencegah komplikasi serius dan meningkatkan peluang kesembuhan pasien. Namun, keterbatasan sumber daya medis serta kompleksitas data klinis menjadi tantangan dalam proses diagnosis yang cepat dan akurat.\n",
        "\n",
        "Indian Liver Patient Dataset (ILPD) menyediakan data klinis dari pasien yang berasal dari India, dan bertujuan untuk membantu pengembangan sistem prediksi penyakit hati berdasarkan parameter medis. Dengan menganalisis data ini, dapat dibangun model prediksi yang efisien untuk mendeteksi pasien yang berisiko terkena penyakit hati.\n",
        "\n",
        "Paper Reference: [Tabular Data Generation to Improve Classification of Liver Disease Diagnosis](https://www.mdpi.com/2076-3417/13/4/2678)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Tujuan Analisis Dataset\n",
        "Tujuan utama dari analisis dataset ini adalah:\n",
        "1. **Mengidentifikasi variabel kunci** yang memengaruhi risiko terkena penyakit hati.\n",
        "2. **Membangun model prediktif** yang dapat membantu memprediksi penyakit hati pada pasien.\n",
        "\n",
        "Dengan hasil analisis ini, diharapkan dataset dapat memberikan wawasan yang berharga kepada rumah sakit, tenaga medis, dan pembuat kebijakan dalam mengurangi penyakit hati.\n",
        "\n",
        "# Terkait Dataset\n",
        "- **Sumber Data**: [UCI Machine Learning Repository – Indian Liver Patient Dataset](https://archive.ics.uci.edu/dataset/225/ilpd+indian+liver+patient+dataset)\n",
        "- **Jumlah Sampel Data**: 583 pasien\n",
        "- **Jumlah Atribut**: 10 atribut, meliputi: age, gender, total Bilirubin, direct Bilirubin, total proteins, albumin, A/G ratio, SGPT, SGOT and Alkphos.\n",
        "- **Label**: 2 (0 = pasien yang memiliki penyakit hati, 1 = pasien yang tidak memiliki penyakit hati).\n",
        "\n",
        "# Pendekatan Analisis\n",
        "Untuk mendukung analisis dataset ini, akan dibuat skema komparasi model prediksi yang dilakukan dengan 2 pendekatan berbeda:\n",
        "\n",
        "1. **Menggunakan SMOTE**: Model akan dibangun dengan memanfaatkan data hasil augmentasi menggunakan Synthetic Minority Oversampling Technique (SMOTE) untuk menangani ketidakseimbangan kelas pada dataset dan meningkatkan performa klasifikasi penyakit hati.\n",
        "\n",
        "2. **Menggunakan Augmentasi GAN**: Model juga akan dibangun dengan menggunakan data sintetis yang dihasilkan melalui Generative Adversarial Networks (GAN), untuk mengevaluasi apakah metode generatif ini dapat menghasilkan data yang lebih representatif dan meningkatkan generalisasi model.\n",
        "\n",
        "Studi ini berfokus pada dataset yang terdiri dari 583 data pasien liver yang dikumpulkan di India, dan bertujuan untuk membandingkan efektivitas dua pendekatan augmentasi data yaitu SMOTE vs GAN dalam meningkatkan performa model klasifikasi penyakit hati.\n",
        "\n"
      ],
      "metadata": {
        "id": "2mFf-EPkYprQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BAB 1 - (J.62DMI00.004.1) Mengumpulkan data\n",
        "- Load Data dan Ganti nama kolom yang masih berupa index dan ganti menjadi berikut pada dataframe :\n",
        "\n",
        "\n",
        "*    'age', 'gender', 'tb', 'db', 'alkphos', 'sgpt', 'sgot',\n",
        "       'tp', 'alb', 'a/g ratio', 'selector'\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xtEQMJIobeFY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Libary"
      ],
      "metadata": {
        "id": "VnLAsM-RP9u7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mx_n7bsbXcnB"
      },
      "outputs": [],
      "source": [
        "# Import Library\n",
        "!pip install ctgan\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from ctgan import CTGAN\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Dataset"
      ],
      "metadata": {
        "id": "FuSyY6ZVQBGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = \"FIXME\""
      ],
      "metadata": {
        "id": "zoTEdiDwLErm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "L5V6z8xZKMOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cek nama kolom\n",
        "\"FIXME\""
      ],
      "metadata": {
        "id": "CgW1eSojKPBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perhatikan nama kolom pada dataset. Gantilah nama-nama kolom yang masih berupa indeks (angka) dengan nama-nama fitur yang sesuai, yaitu: 'age', 'gender', 'tb', 'db', 'alkphos', 'sgpt', 'sgot', 'tp', 'alb', 'a/g ratio', dan 'selector'."
      ],
      "metadata": {
        "id": "PFzMeSHwKY5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols =[\"FIXME\"]\n",
        "\n",
        "# Mengganti nama kolom dataframe dengan cols\n",
        "df.columns = cols"
      ],
      "metadata": {
        "id": "CnPZAqrMdkO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BAB 2 – (J.62DMI00.005.1) Menelaah data"
      ],
      "metadata": {
        "id": "FBtaaWjLb-nP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mengecek Value"
      ],
      "metadata": {
        "id": "fo3tkl7NQPHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan data setelah nama kolom berhasil diganti. (5 kolom teratas)\n",
        "\"FIXME\""
      ],
      "metadata": {
        "id": "11A4zxD1dmmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Pada tahap ini, kita akan menelaah data yang ada pada dataset `Liver Patient Dataset (ILPD)`. Kita akan melihat informasi data, statistik deskriptif, dan distribusi data."
      ],
      "metadata": {
        "id": "fYJVHKHuebMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan data setelah nama kolom berhasil diganti. (5 kolom terbawah)\n",
        "\"FIXME\""
      ],
      "metadata": {
        "id": "MSSP6u9AQSdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Melihat dimensi"
      ],
      "metadata": {
        "id": "RIwM2HgodLKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan dimensi Dataset\n",
        "\"FIXME\""
      ],
      "metadata": {
        "id": "briRQIh7dmuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Melihat informasi dataset"
      ],
      "metadata": {
        "id": "KqDsX082drj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melihat Informasi Dataset\n",
        "\"FIXME\""
      ],
      "metadata": {
        "id": "PVdRI88Mj6Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Melihat deskripsi statistik"
      ],
      "metadata": {
        "id": "KKbCcIqfQoWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melihat Deskripsi statistik\n",
        "\"FIXME\""
      ],
      "metadata": {
        "id": "LxENhQrfj8p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Melihat persebaran data"
      ],
      "metadata": {
        "id": "th6xBQjaQtj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# menampilkan diagram histplot untuk telaah semua feature\n",
        "df.hist(figsize=(15, 15))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aKq7wuHTLTKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# membuat fungsi untuk melakukan observasi pada dataset\n",
        "def grab_col_names(dataframe, cat_th = 10, car_th = 20): #  memisahkan kolom dalam dataset berdasarkan tipe dan karakteristiknya.\n",
        "\n",
        "    cat_cols = [col for col in dataframe.columns if str(dataframe[col].dtypes) in [\"category\", \"object\", \"bool\"]] # kolom kategorikal (tipe \"category\", \"object\", \"bool\", atau numerik dengan unique values < cat_th).\n",
        "    num_but_cat = [col for col in dataframe.columns if str(dataframe[col].dtypes) in [\"int64\", \"float64\"] and dataframe[col].nunique() < cat_th] # kolom numerik yang bertindak seperti kategorikal (berdasarkan jumlah unique values).\n",
        "    cat_but_car = [col for col in dataframe.columns if str(dataframe[col].dtypes) in [\"category\", \"object\"] and dataframe[col].nunique() > car_th] # kolom kategorikal dengan unique values > car_th (high cardinality).\n",
        "\n",
        "    cat_cols = cat_cols + num_but_cat\n",
        "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
        "\n",
        "    # kolom numerik murni (int64, float64) yang bukan kategorikal.\n",
        "    num_cols = [col for col in dataframe.columns if str(dataframe[col].dtypes) in [\"int64\", \"float64\"]]\n",
        "    num_cols = [col for col in num_cols if col not in cat_cols]\n",
        "\n",
        "    print(f\"Jumlah observasi: {dataframe.shape[0]}\")\n",
        "    print(f\"Jumlah variabel: {dataframe.shape[1]}\")\n",
        "    print(f\"Kolom kategorikal: {len(cat_cols)}\")\n",
        "    print(f\"Kolom Numerik: {len(num_cols)}\")\n",
        "    print(f\"Kategori tapi kardinal: {len(cat_but_car)}\")\n",
        "    print(f\"Numerik tapi kategorikal: {len(num_but_cat)}\")\n",
        "\n",
        "    # mengembalikan daftar kolom yang dikelompokkan berdasarkan tipe (cat_cols, num_cols, cat_but_car).\n",
        "    return cat_cols, num_cols, cat_but_car"
      ],
      "metadata": {
        "id": "ket_1X_XLZhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols, num_cols, cat_but_car = \"FIXME\"(df)"
      ],
      "metadata": {
        "id": "QDVTPVupLcPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Nominal Feature"
      ],
      "metadata": {
        "id": "OxV0fHhY75Am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisasikan fitur nominal / kategorikal misal (menggunakan countplot)\n",
        "for col in cat_cols:\n",
        "    countplot = sns.countplot(data=df, x=col)\n",
        "    plt.title(f'Countplot of {col}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_GoG3m8JeHkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Continous features"
      ],
      "metadata": {
        "id": "CJFXAG3J7-D6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisasikan fitur numerik continous (misal : histplot)\n",
        "for col in num_cols:\n",
        "    histplot = sns.histplot(data=df, x=col)\n",
        "    plt.title(f'Histogram of {col}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "vLcARCtveZpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BAB 3 – (J.62DMI00.006.1) memvalidasi data"
      ],
      "metadata": {
        "id": "HlepCGhNervb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Pada tahap ini, kita akan mengecek apakah terdapat data yang hilang atau tidak, terdapat duplikat atau tidak, dan apakah terdapat data yang tidak konsisten (bisa melakukan pengecekan nilai unik)"
      ],
      "metadata": {
        "id": "ioJcLfRXYAG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Memeriksa nilai kosong (missing value)"
      ],
      "metadata": {
        "id": "aMTKkUKsQ1l1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melihat Nilai null / missing value\n",
        "df.\"FIXME\"().sum()"
      ],
      "metadata": {
        "id": "bTkwAPXZjhwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Memeriksa duplikat data"
      ],
      "metadata": {
        "id": "yVZxft5xQ28s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melihat Data duplikat\n",
        "df.\"FIXME\"().sum()"
      ],
      "metadata": {
        "id": "uxjhiIESjlFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Duplikat:\", df.\"FIXME\"().sum())"
      ],
      "metadata": {
        "id": "MrnQ3voTLzzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melihat Data duplikat\n",
        "df.\"FIXME\"().sum()\n",
        "df[df.\"FIXME\"(keep=False)]"
      ],
      "metadata": {
        "id": "rjQ6pqdcRUm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Memeriksa nilai unique"
      ],
      "metadata": {
        "id": "m3Ue3MmLRCUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.\"FIXME\"()"
      ],
      "metadata": {
        "id": "qJaR7XibRXwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.columns:\n",
        " print(f'{col}')\n",
        " print(f'Jumlah nilai yang unik: {df[col].nunique()}')\n",
        " print(f'Nilai yang paling sering muncul (modus): {df[col].mode().values[0]}')\n",
        " print(f'{df[col].unique()}\\n')"
      ],
      "metadata": {
        "id": "3W61YSfZRZ9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# melihat apakah ada data yang tidak konsisten\n",
        "df[\"FIXME\"].value_counts()"
      ],
      "metadata": {
        "id": "N5KEqHaYMDQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BAB 4 – (J.62DMI00.007.1) menentukan object data"
      ],
      "metadata": {
        "id": "43FQZUVxfQw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WAJIB DIISI**,\n",
        "\n",
        "ADA BERAPA FITUR: `ISI DISINI`\n",
        "\n",
        "ADA BERAPA RECORDS: `ISI DISINI`\n",
        "\n",
        "ADA BERAPA FITUR YANG TIDAK DIGUNAKAN: `ISI DISINI`\n",
        "\n",
        "TARGETNYA APA: `ISI DISINI`\n",
        "\n",
        "ADA BERAPA MODEL DATAFRAME YANG HARUS DIBUAT?: `ISI DISINI`"
      ],
      "metadata": {
        "id": "DG6RzyFpfL3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melihat kembali informasi dataset untuk memahami isi dan tipe data"
      ],
      "metadata": {
        "id": "H-oavbaJkI0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Jika ada data yang tidak konsisten, silahkan di tangani pada proses dibawah ini."
      ],
      "metadata": {
        "id": "8D7_uzOsfvTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# jika terdapat data yang tidak konsisten"
      ],
      "metadata": {
        "id": "j8m_TUzefc70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Jika ada fitur yang tidak berguna, bisa dihapus pada cell dibawah ini"
      ],
      "metadata": {
        "id": "GXijZ0Eqf7iG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# jika terdapar fitur yang tidak berguna"
      ],
      "metadata": {
        "id": "ujOI8QvLgB55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mengubah label target"
      ],
      "metadata": {
        "id": "ZeLRkld8SXyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ubah label target menjadi 0 dan 1\n",
        "df[\"FIXME\"] = df[\"FIXME\"].map({\"FIXME\": 0, \"FIXME\": 1})"
      ],
      "metadata": {
        "id": "cb_zPHXWMaOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BAB 5 – (J.62DMI00.008.1) membersihkan data\n",
        "- **ANDA TIDAK PERLU MELAKUKAN OUTLIER REMOVAL** NAMUN HANDLE JIKA TERDAPAT DATA YANG KOSONG (TIDAK DIREKOMENDASIKAN MENGHAPUS), HANDLE JIKA ADA DUPLIKAT"
      ],
      "metadata": {
        "id": "nIDQTlnegLrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Memeriksa missing values"
      ],
      "metadata": {
        "id": "nzH3c_OxSeD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memastikan kembali untuk melihat data kosong\n",
        "df.\"FIXME\"().sum()"
      ],
      "metadata": {
        "id": "Mlvuo1mSgE2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling missing values\n",
        "\n",
        "Ada aturan tidak baku dalam data science:\n",
        "*   jika missing value lebih dari 60% maka lebih baik dilakukan `drop feature`\n",
        "*   Jika hanya terdapat sedikit missing values (kurang dari 5%) dan data tidak mengandung informasi penting maka lebih baik dilakukan `drop baris` agar tidak mengubah distribusi fitur lainnya\n",
        "*  Jika data bersifat numerik, data tidak memiliki outlier yang ekstrem, jumlah missing values lebih dari 5%, jumlah missing values kurang dari 60% dan distribusi data mendekati normal maka lebih baik dilakukan `imputasi menggunakan mean`\n",
        "*   Jika data bersifat numerik, data memiliki outlier yang tidak ekstrem, jumlah missing values lebih dari 5%, jumlah missing values kurang dari 60% dan berdistribusi tidak normal maka lebih baik dilakukan `imputasi median`\n",
        "*   Jika data bersifat kategorikal, jumlah missing value kurang dari 60%, dan lebih dari 5% maka lebih baik dilakukan `imputasi modus`"
      ],
      "metadata": {
        "id": "rtvIjouiSk8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling baris yang memiliki NaN di kolom 'a/g ratio'\n",
        "df = df.\"FIXME\"(subset=[\"FIXME\"])"
      ],
      "metadata": {
        "id": "-i-zSQzWgucx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling duplikat data"
      ],
      "metadata": {
        "id": "PaYoBCnWSsAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek duplikasi data & Handle jika terdapat duplikat data\n",
        "df = df.\"FIXME\"()"
      ],
      "metadata": {
        "id": "OlEweBMxhIA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Dari pekerjaan Membersihkan Data yang telah anda lakukan, Bagaimana yang akan anda lakukan jika Dataset anda ternyata memiliki beberapa nilai kosong (missing value)? `ISI DISINI`"
      ],
      "metadata": {
        "id": "3is-ZvsuV1m8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BAB 6 – (J.62DMI00.009.1) mengkonstruksi data\n",
        "CATATAN:\n",
        "- **UNTUK UJIAN INI, ANDA TIDAK PERLU MELAKUKAN FEATURE ENGINEERING DISINI**\n",
        "- NAMUN ANDA WAJIB MELAKUKAN SAMPLING UNTUK BALANCING CLASS (MENYEIMBANGKAN KELAS DENGAN SKEMA OVER SAMPLING), MENUNJUKKAN OUTLIER YANG TERDAPAT PADA DATASETS, DAN MENAMPILKAN HEATMAP KORELASI ANTAR FITUR UNTUK MENGETAHUI FITUR - FITUR YANG MEMILIKI KORELASI TINGGI DAN RENDAH PADA DATASETS"
      ],
      "metadata": {
        "id": "l8VZ7J86hSAx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deteksi Outlier"
      ],
      "metadata": {
        "id": "4jVevQBQS0GJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cek outlier dengan visualisasi\n",
        "for col in num_cols:\n",
        "    boxplot = sns.boxplot(data=df, x=col)\n",
        "    plt.title(f'Boxplot of {col}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "8GAnWQvQiW8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Handling dengan IQR"
      ],
      "metadata": {
        "id": "YV01nzmbPTKh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ingat, handling dengan IQR disini jika distribusi data tidak normal (tidak simetris atau skewed), dimana ada data yang outliersnya positively skewed (miring kanan/condong di kanan) atau negatively skewed (miring kiri/condong di kiri)\n",
        "\n"
      ],
      "metadata": {
        "id": "6jtuGIeTOHgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Buat salinan dataframe\n",
        "data_cleaned = df.copy()"
      ],
      "metadata": {
        "id": "BzydhOujPfZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iqr_cols = ['tb', 'db', 'alkphos', 'sgpt', 'sgot',\n",
        "       'a/g ratio']\n",
        "\n",
        "for col in iqr_cols:\n",
        "    Q1 = 'FIXME'[col].quantile(0.25)\n",
        "    Q3 = data_cleaned[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    data_cleaned[col] = data_cleaned[col].apply(\n",
        "        lambda x: lower_bound if x < lower_bound else (upper_bound if x > upper_bound else x)\n",
        "    )\n",
        "    print(f\"Kolom {col} telah diatasi outliersnya dengan IQR.\")"
      ],
      "metadata": {
        "id": "pg6jUwBcN82V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Handling dengan Zscore"
      ],
      "metadata": {
        "id": "Wdb9Ly4DOT0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ingat, handling dengan Zscore disini jika data yang berdistribusi normal atau mendekati normal (simetris) atau seimbang outliersnya antara kanan dan kiri.\n"
      ],
      "metadata": {
        "id": "A7F_30xxOLLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zscore_cols = ['FIXME']\n",
        "\n",
        "for col in zscore_cols:\n",
        "    mean = data_cleaned[col].mean()\n",
        "    std = data_cleaned[col].std()\n",
        "    threshold = 3  # z-score threshold\n",
        "\n",
        "    data_cleaned[col] = data_cleaned[col].apply(\n",
        "        lambda x: mean - threshold * std if (x - mean)/std < -threshold\n",
        "        else (mean + threshold * std if (x - mean)/std > threshold else x)\n",
        "    )\n",
        "    print(f\"Kolom {col} telah diatasi outliersnya dengan Z-score.\")"
      ],
      "metadata": {
        "id": "sqarosaFOR36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = data_cleaned"
      ],
      "metadata": {
        "id": "XhRIlew3PiSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cek outlier dengan visualisasi (misalnya menggunakan boxplot)\n",
        "plt.figure(figsize=(15, 8))\n",
        "sns.boxplot(data=df.drop('selector', axis=1))\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Boxplot Semua Fitur\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T381Qs2YPprz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mengubah kolom ke numerik"
      ],
      "metadata": {
        "id": "O11ROyoTbtw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "vQLc-wllQcNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_cols = [\"FIXME\"]"
      ],
      "metadata": {
        "id": "ZVCzAChkQAJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in enc_cols:\n",
        "    df[col] = LabelEncoder().fit_transform(df[col])"
      ],
      "metadata": {
        "id": "plxZN7JAbqHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Heatmap Correlation"
      ],
      "metadata": {
        "id": "MmAOik6hTBA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# melihat korelasi antar fitur (heatmap)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title(\"Heatmap Korelasi Fitur\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pmAaVlKVijkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- PADA TAHAP SELANJUTNYA, SILAHKAN BANDINGKAN HASIL PEMODELAN KETIKA MENGGUNAKAN DATA YANG TELAH DIAUGMENTASI MENGGUNAKAN GAN DENGAN DATA YANG DIAUGMENTASI MENGGUNAKAN SMOTE.\n",
        "\n",
        "- SETELAH ITU, JAWAB PERTANYAAN BERIKUT:\n",
        "  - DARI RATA-RATA SEMUA MODEL YANG DIBANDINGKAN (RF, KNN, DAN LOGISTIC REGRESSION), AKURASI YANG DIDAPATKAN LEBIH TINGGI MENGGUNAKAN AUGMENTASI GAN ATAU SMOTE? : `ISI DI SINI`"
      ],
      "metadata": {
        "id": "X98UxED8itG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BAB 7 – (J.62DMI00.010.1) menentukan label data"
      ],
      "metadata": {
        "id": "9pmDKoCJkgHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Gunakan 3 nama variabel yang berbeda untuk proses splitting dataset berdasarkan metode augmentasi yang digunakan, yaitu untuk SMOTE dan GAN:\n",
        "\n",
        "*   Untuk dataset hasil augmentasi SMOTE:\n",
        "1. `X_smote` = Untuk menampung dataset yang telah diaugmentasi menggunakan SMOTE.\n",
        "2. `y_smote` = Untuk menampung target / kelas yang akan diprediksi dari dataset SMOTE.\n",
        "3. `X_train_smote, X_test_smote, y_train_smote, y_test_smote` = Untuk menampung data hasil train_test_split menggunakan `X_smote` dan `y_smote`.\n",
        "\n",
        "*  Untuk dataset hasil augmentasi GAN:\n",
        "1. `X_gan` = Untuk menampung dataset yang telah diaugmentasi menggunakan GAN.\n",
        "2. `y_gan` = Untuk menampung target / kelas yang akan diprediksi dari dataset GAN.\n",
        "3. `X_train_gan, X_test_gan, y_train_gan, y_test_gan` = Untuk menampung data hasil train_test_split menggunakan `X_gan` dan `y_gan`."
      ],
      "metadata": {
        "id": "7dfdUkdHkwWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- yang menjadi target adalah: `ISI DISINI`\n",
        "- yang menjadi fitur adalah : `ISI DISINI`"
      ],
      "metadata": {
        "id": "PA-WFyA3kjdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "BU5ddWLKTh_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting"
      ],
      "metadata": {
        "id": "vCMm8keqcqWe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Splitting untuk GAN"
      ],
      "metadata": {
        "id": "y2QFQI57TLMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# memisalkah fitur dan target\n",
        "X_gan = df.drop(\"FIXME\", axis=1)\n",
        "y_gan = df[\"FIXME\"]"
      ],
      "metadata": {
        "id": "KAiDvgGkJTir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data untuk GAN\n",
        "X_train_gan, X_test_gan, y_train_gan, y_test_gan = train_test_split(\"FIXME\", \"FIXME\", stratify=y_gan, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "_Bc6OGFemWVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Splitting untuk SMOTE"
      ],
      "metadata": {
        "id": "Vf6Kbu9mY91r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# memisalkah fitur dan target\n",
        "X_smote = df.drop(\"FIXME\", axis=1)\n",
        "y_smote = df[\"FIXME\"]"
      ],
      "metadata": {
        "id": "ctX1qrJlY918"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data untuk SMOTE\n",
        "X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(\"FIXME\", \"FIXME\", stratify=y_smote, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "byCgCTOXY91-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Balancing data Imbalance"
      ],
      "metadata": {
        "id": "gf5r1cspUMBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Distribusi kelas di train (original):\")\n",
        "print(y_train_smote.value_counts())\n",
        "sns.countplot(x=y_train_smote)\n",
        "plt.title(\"Distribusi Kelas Train Asli\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lnvZAOrsxEu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SMOTE"
      ],
      "metadata": {
        "id": "uPnpWi0iRMTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# karena jumlah kelas target tidak seimbang, kita akan melakukan resampling\n",
        "smote = \"FIXME\"(random_state=42)\n",
        "X_smote_resampled, y_smote_resampled = smote.fit_resample(\"FIXME\", y_train_smote)"
      ],
      "metadata": {
        "id": "T_TVZIrWiBh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tampilkan visualisasi persebaran kelas setelah melalui proses sampling\n",
        "print(\"Distribusi kelas setelah SMOTE:\")\n",
        "print(pd.Series(y_smote_resampled).value_counts())\n",
        "sns.countplot(x=y_smote_resampled)\n",
        "plt.title(\"Distribusi Kelas SMOTE\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iGWAoRMHEzUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GAN"
      ],
      "metadata": {
        "id": "CmI1vu26fw-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ubah ke DataFrame agar cocok dengan CTGAN\n",
        "X_train_gan_scaled_df = pd.DataFrame(X_train_gan, columns=X_train_gan.columns)\n",
        "X_train_gan_scaled_df['FIXME'] = y_train_gan.values\n",
        "\n",
        "# Mengambil data minoritas untuk dilatin dengan GAN\n",
        "minority_class = y_train_gan.value_counts().idxmin()\n",
        "minority_data = X_train_gan_scaled_df[X_train_gan_scaled_df['selector'] == minority_class]\n",
        "\n",
        "# Latih dengan CTGAN\n",
        "ctgan = CTGAN()\n",
        "ctgan.fit(minority_data)\n",
        "\n",
        "# Tentukan berapa data sintetis yang ingin dihasilkan\n",
        "minority_count = y_train_gan.value_counts().min()\n",
        "majority_count = y_train_gan.value_counts().max()\n",
        "n_samples_to_generate = majority_count - minority_count\n",
        "\n",
        "# Hasilkan data sintetis dari kelas minoritas\n",
        "synthetic_data = ctgan.sample(n_samples_to_generate)\n",
        "\n",
        "# Gabungkan kembali data sintetis dengan data asli\n",
        "augmented_train_data = pd.concat([X_train_gan_scaled_df, synthetic_data], ignore_index=True)\n",
        "\n",
        "# Pisahkan kembali fitur dan target setelah augmentasi\n",
        "X_gan_resampled = augmented_train_data.drop(columns='selector')\n",
        "y_gan_resampled = augmented_train_data['selector']"
      ],
      "metadata": {
        "id": "JxbbofQagtb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tampilkan visualisasi persebaran kelas setelah melalui proses sampling\n",
        "print(\"Distribusi kelas setelah GAN:\")\n",
        "print(pd.Series(y_gan_resampled).value_counts())\n",
        "sns.countplot(x=y_gan_resampled)\n",
        "plt.title(\"Distribusi Kelas GAN\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vPuYh9Zug5k4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalisasi"
      ],
      "metadata": {
        "id": "F9hldM1Rh8ch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ANDA PERLU MELAKUKAN NORMALISASI DISINI"
      ],
      "metadata": {
        "id": "dF7ZVb28l9dK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# proses normalisasi / scalling\n",
        "scaler_smote = RobustScaler()\n",
        "X_train_smote_scaled = \"FIXME\".fit_transform(X_smote_resampled)\n",
        "X_test_smote_scaled = \"FIXME\".transform(X_test_smote)\n",
        "\n",
        "scaler_gan = RobustScaler()\n",
        "X_train_gan_scaled = \"FIXME\".fit_transform(X_gan_resampled)\n",
        "X_test_gan_scaled = \"FIXME\".transform(X_test_gan)"
      ],
      "metadata": {
        "id": "U5-3M0SUluwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Dari pekerjaan Mengkonstruksi Data yang telah anda lakukan, bagaimana cara Anda menentukan fitur-fitur pada dataset anda perlu dinormalisasi atau tidak? : 'ISI DISINI'"
      ],
      "metadata": {
        "id": "hukyz1XKG56f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BAB 8 – (J.62DMI00.013.1) membangun model\n",
        "- BANGUN MODEL DENGAN MENGGUNAKAN ALGORITMA KLASIFIKASI SEPERTI RANDOM FOREST (RF), K-NEAREST NEIGHBOUR (KNN), DAN LOGISTIC REGRESSION (LR) UNTUK KEDUA DATASET (MEMAKAI AUGMENTASI GAN & MEMAKAI AUGMENTASI SMOTE)"
      ],
      "metadata": {
        "id": "pOd56ErQm89M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, X_train_data, y_train_data, X_test_data, y_test_data, model_name):\n",
        "    model.fit(X_train_data, y_train_data)\n",
        "    y_pred = model.predict(X_test_data)\n",
        "    print(f\"=== {model_name} ===\")\n",
        "    print(classification_report(y_test_data, y_pred))\n",
        "    sns.heatmap(confusion_matrix(y_test_data, y_pred), annot=True, fmt='d', cmap='viridis')\n",
        "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3QrAw2eFyupN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ],
      "metadata": {
        "id": "0JaVhl29n25a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = \"FIXME\"(probability=True, random_state=42)\n",
        "\n",
        "print(\"SVM dengan SMOTE\")\n",
        "eval_model(svm, X_train_smote_scaled, y_smote_resampled, X_test_smote_scaled, y_test_smote, \"SVM - SMOTE\")"
      ],
      "metadata": {
        "id": "NXhQoxWDMXIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SVM dengan GAN\")\n",
        "eval_model(svm, \"FIXME\", y_gan_resampled, X_test_gan_scaled, y_test_gan, \"SVM - GAN\")"
      ],
      "metadata": {
        "id": "VxkhRaPRuYAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree"
      ],
      "metadata": {
        "id": "kJwXHhZsMMbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt = \"FIXME\"(random_state=42)\n",
        "\n",
        "print(\"Decision Tree dengan SMOTE\")\n",
        "eval_model(dt, X_train_smote_scaled, \"FIXME\", X_test_smote_scaled, y_test_smote, \"Decision Tree - SMOTE\")\n"
      ],
      "metadata": {
        "id": "GYigYgp4n1DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Decision Tree dengan GAN\")\n",
        "eval_model(dt, X_train_gan_scaled, y_gan_resampled, X_test_gan_scaled, y_test_gan, \"Decision Tree - GAN\")"
      ],
      "metadata": {
        "id": "j80ruYW6vSzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "TG3j2HyVoCIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = \"FIXME\"()\n",
        "\n",
        "print(\"KNN dengan SMOTE\")\n",
        "eval_model(knn, X_train_smote_scaled, y_smote_resampled, X_test_smote_scaled, y_test_smote, \"KNN - SMOTE\")\n"
      ],
      "metadata": {
        "id": "ufHf-O_7n87s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"KNN dengan GAN\")\n",
        "eval_model(knn, X_train_gan_scaled, y_gan_resampled, X_test_gan_scaled, y_test_gan, \"KNN - GAN\")"
      ],
      "metadata": {
        "id": "YpYTvnSQvs4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "fNjuj7Vivdgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = \"FIXME\"(max_iter=1000, random_state=42)\n",
        "\n",
        "print(\"Logistic Regression dengan SMOTE\")\n",
        "eval_model(\"FIXME\", X_train_smote_scaled, y_smote_resampled, X_test_smote_scaled, y_test_smote, \"Logistic Regression - SMOTE\")\n"
      ],
      "metadata": {
        "id": "0OdPcxwOv0mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Logistic Regression dengan GAN\")\n",
        "eval_model(logreg, X_train_gan_scaled, y_gan_resampled, X_test_gan_scaled, y_test_gan, \"Logistic Regression - GAN\")"
      ],
      "metadata": {
        "id": "UW-9T3pFwZaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Dari pekerjaan Membangun Model yang telah anda lakukan, bagaimana cara Anda meningkatkan hasil akurasi pada sebuah model? : `ISI DISINI`"
      ],
      "metadata": {
        "id": "lhgP-XO8GkTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BAB 9 – (J.62DMI00.014.1) mengevaluasi hasil pemodelan\n",
        "- BANDINGKAN SEMUA MODEL UNTUK MENGETAHUI MODEL MANA YANG MEMILIKI AKURASI YANG TINGGI"
      ],
      "metadata": {
        "id": "epQAfmdtojYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi model dasar\n",
        "svm = SVC(probability=True, random_state=42)\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "knn = KNeighborsClassifier()\n",
        "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# SMOTE\n",
        "svm.fit(X_train_smote_scaled, y_smote_resampled)\n",
        "svm_smote_acc = accuracy_score(y_test_smote, svm.predict(X_test_smote_scaled))\n",
        "\n",
        "dt.fit(X_train_smote_scaled, y_smote_resampled)\n",
        "dt_smote_acc = accuracy_score(y_test_smote, dt.predict(X_test_smote_scaled))\n",
        "\n",
        "knn.fit(X_train_smote_scaled, y_smote_resampled)\n",
        "knn_smote_acc = accuracy_score(y_test_smote, knn.predict(X_test_smote_scaled))\n",
        "\n",
        "logreg.fit(X_train_smote_scaled, y_smote_resampled)\n",
        "logreg_smote_acc = accuracy_score(y_test_smote, logreg.predict(X_test_smote_scaled))\n",
        "\n",
        "# GAN\n",
        "svm.fit(X_train_gan_scaled, y_gan_resampled)\n",
        "svm_gan_acc = accuracy_score(y_test_gan, svm.predict(X_test_gan_scaled))\n",
        "\n",
        "dt.fit(X_train_gan_scaled, y_gan_resampled)\n",
        "dt_gan_acc = accuracy_score(y_test_gan, dt.predict(X_test_gan_scaled))\n",
        "\n",
        "knn.fit(X_train_gan_scaled, y_gan_resampled)\n",
        "knn_gan_acc = accuracy_score(y_test_gan, knn.predict(X_test_gan_scaled))\n",
        "\n",
        "logreg.fit(X_train_gan_scaled, y_gan_resampled)\n",
        "logreg_gan_acc = accuracy_score(y_test_gan, logreg.predict(X_test_gan_scaled))\n"
      ],
      "metadata": {
        "id": "NBs6_mreoLpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nama model\n",
        "model_names = [\n",
        "    'SVM (SMOTE)', 'DT (SMOTE)', 'KNN (SMOTE)', 'LogReg (SMOTE)',\n",
        "    'SVM (GAN)', 'DT (GAN)', 'KNN (GAN)', 'LogReg (GAN)'\n",
        "]\n",
        "\n",
        "# Akurasi dari semua model\n",
        "accuracies = [\n",
        "    svm_smote_acc, dt_smote_acc, knn_smote_acc, logreg_smote_acc,\n",
        "    svm_gan_acc, dt_gan_acc, knn_gan_acc, logreg_gan_acc\n",
        "]\n",
        "\n",
        "# Buat DataFrame untuk plotting\n",
        "df_result = pd.DataFrame({\n",
        "    'Model': model_names,\n",
        "    'Accuracy': accuracies,\n",
        "    'Augmentation': ['SMOTE'] * 4 + ['GAN'] * 4\n",
        "})\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Model', y='Accuracy', hue='Augmentation', data=df_result, palette='Set2')\n",
        "plt.title(\"Perbandingan Akurasi Model SMOTE VS GAN\")\n",
        "plt.ylabel(\"Akurasi\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylim(0.5)\n",
        "plt.xticks(rotation=30)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JEMkNbfh_FKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- MODEL YANG MEMILIKI AKURASI TINGGI ? : `ISI DISINI`\n",
        "- Dari pekerjaan Mengevaluasi Hasil Pemodelan yang telah anda lakukan, bagaimana cara Anda menentukan model yang lebih akurat dan terbaik dari beberapa model yang telah anda bangun? : `ISI DISINI`\n",
        "- Jelaskan"
      ],
      "metadata": {
        "id": "r3HDZ2EFtXQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BAB 10 - Optimasi model klasifikasi\n"
      ],
      "metadata": {
        "id": "tsBQHvxtG4T2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada bab ini, proses optimasi difokuskan pada model yang memiliki akurasi tertinggi berdasarkan hasil perbandingan antara dua metode augmentasi data, yaitu SMOTE dan GAN. Model dengan performa terbaik, baik dari segi akurasi maupun metrik evaluasi lainnya dipilih untuk dilakukan proses tuning lebih lanjut guna memperoleh hasil klasifikasi yang lebih optimal.\n",
        "Model apa yang memiliki akurasi lebih tinggi dari hasil perbandingan dua metode augmentasi? (MODEL AUGMENTASI GAN ATAU MODEL AUGMENTASI SMOTE?) `ISI DISINI`\n",
        "\n"
      ],
      "metadata": {
        "id": "GJgzMSSIUUM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ],
      "metadata": {
        "id": "7l18acfJHKhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_params = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf']\n",
        "}\n"
      ],
      "metadata": {
        "id": "rVIypwvHHUdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "svm_random = GridSearchCV(SVC(probability=True, random_state=42),\n",
        "                                \"FIXME\",\n",
        "                                cv=2, scoring='accuracy',\n",
        "                                n_jobs=-1,\n",
        "                                verbose=1)\n",
        "\"FIXME\".fit(X_train_gan_scaled, y_gan_resampled)\n",
        "best_svm = svm_random.best_estimator_\n",
        "y_svm_pred = \"FIXME\".predict(X_test_gan_scaled)"
      ],
      "metadata": {
        "id": "TccdIusZIUO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Optimized SVM - Best Parameters:\", svm_random.best_params_)\n",
        "print(\"FIXME\"(y_test_gan, y_svm_pred))\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test_gan, y_svm_pred), annot=True, fmt='d', cmap='viridis')\n",
        "plt.title(\"Confusion Matrix - Optimized SVM\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SRIT7atsHjlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree"
      ],
      "metadata": {
        "id": "47HJVccFHOI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_params = {\n",
        "    'max_depth': [3, 5, 10, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}"
      ],
      "metadata": {
        "id": "TzyKf6LXJYOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_grid = GridSearchCV(DecisionTreeClassifier(random_state=42),\n",
        "                       \"FIXME\",\n",
        "                       cv=5,\n",
        "                       scoring='accuracy',\n",
        "                       n_jobs=-1,\n",
        "                       verbose=1)\n",
        "dt_grid.fit(X_train_gan_scaled, y_gan_resampled)\n",
        "\n",
        "best_dt = dt_grid.best_estimator_\n",
        "y_dt_pred = \"FIXME\".predict(X_test_gan_scaled)"
      ],
      "metadata": {
        "id": "7uZZ2ljxJb0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Optimized Decision Tree - Best Parameters:\", dt_grid.best_params_)\n",
        "print(classification_report(y_test_gan, y_dt_pred))\n",
        "\n",
        "sns.heatmap(\"FIXME\"(y_test_gan, y_dt_pred), annot=True, fmt='d', cmap='viridis')\n",
        "plt.title(\"Confusion Matrix - Optimized Decision Tree\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i9Ho3Ry0KYdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "TyBw3hN0HQan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn_params = {\n",
        "    'n_neighbors': [3, 5, 7, 9],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan']\n",
        "}"
      ],
      "metadata": {
        "id": "53Dx8bIxHHvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\"FIXME\".fit(X_train_gan_scaled, y_gan_resampled)\n",
        "\n",
        "best_knn = knn_grid.best_estimator_\n",
        "y_knn_pred = \"FIXME\".predict(X_test_gan_scaled)"
      ],
      "metadata": {
        "id": "K4_Tx6ZCM1dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Optimized KNN - Best Parameters:\", knn_grid.best_params_)\n",
        "print(classification_report(\"FIXME\", y_knn_pred))\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test_gan, y_knn_pred), annot=True, fmt='d', cmap='viridis')\n",
        "plt.title(\"Confusion Matrix - Optimized KNN\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "50glnGiWNr77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "HXixhjYa1uMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_params = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'solver': ['liblinear', 'lbfgs'],\n",
        "    'penalty': ['l2']\n",
        "}\n"
      ],
      "metadata": {
        "id": "J-1BeOTN1yZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_grid = GridSearchCV(\"FIXME\"(max_iter=1000, random_state=42), lr_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "lr_grid.fit(X_train_gan_scaled, y_gan_resampled)\n",
        "best_lr = \"FIXME\".best_estimator_\n",
        "y_lr_pred = best_lr.predict(X_test_gan_scaled)"
      ],
      "metadata": {
        "id": "9sSNMXNA13ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Optimized Logistic Regression - Best Parameters:\", lr_grid.best_params_)\n",
        "print(classification_report(y_test_gan, \"FIXME\"))\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test_gan, y_lr_pred), annot=True, fmt='d', cmap='viridis')\n",
        "plt.title(\"Confusion Matrix - Optimized Logistic Regression\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YrZrhVUy15z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Comparison"
      ],
      "metadata": {
        "id": "dQYNfB8fPOxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Akurasi SEBELUM Optimasi\n",
        "svm_base = SVC(probability=True, random_state=42)\n",
        "dt_base = DecisionTreeClassifier(random_state=42)\n",
        "knn_base = KNeighborsClassifier()\n",
        "logreg_base = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "svm_base.fit(X_train_gan_scaled, y_gan_resampled)\n",
        "svm_before_acc = accuracy_score(y_test_gan, svm_base.predict(X_test_gan_scaled))\n",
        "\n",
        "dt_base.fit(X_train_gan_scaled, y_gan_resampled)\n",
        "dt_before_acc = accuracy_score(y_test_gan, dt_base.predict(X_test_gan_scaled))\n",
        "\n",
        "knn_base.fit(X_train_gan_scaled, y_gan_resampled)\n",
        "knn_before_acc = accuracy_score(y_test_gan, knn_base.predict(X_test_gan_scaled))\n",
        "\n",
        "logreg_base.fit(X_train_gan_scaled, y_gan_resampled)\n",
        "logreg_before_acc = accuracy_score(y_test_gan, logreg_base.predict(X_test_gan_scaled))\n",
        "\n",
        "# Akurasi SESUDAH Optimasi GAN\n",
        "svm_after_acc = accuracy_score(y_test_gan, best_svm.predict(X_test_gan_scaled))\n",
        "dt_after_acc = accuracy_score(y_test_gan, best_dt.predict(X_test_gan_scaled))\n",
        "knn_after_acc = accuracy_score(y_test_gan, best_knn.predict(X_test_gan_scaled))\n",
        "logreg_after_acc = accuracy_score(y_test_gan, best_lr.predict(X_test_gan_scaled))\n"
      ],
      "metadata": {
        "id": "jEmztKMIPLm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_df = pd.DataFrame({\n",
        "    'Model': ['SVM', 'Decision Tree', 'KNN', 'Logistic Regression'] * 2,\n",
        "    'Accuracy': [svm_before_acc, dt_before_acc, knn_before_acc, logreg_before_acc,\n",
        "                 svm_after_acc, dt_after_acc, knn_after_acc, logreg_after_acc],\n",
        "    'Optimization': ['Before'] * 4 + ['After'] * 4\n",
        "})\n",
        "\n",
        "# plotting\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=compare_df, x='Model', y='Accuracy', hue='Optimization', palette='coolwarm')\n",
        "plt.title('Perbandingan Akurasi Sebelum dan Sesudah Optimasi (GAN)')\n",
        "plt.ylim(0.5)\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dgmWBjTosfzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dktGAd3F6zNZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}